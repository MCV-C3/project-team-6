wandb: WARNING The anonymous setting has no effect and will be removed in a future version.
wandb: [wandb.login()] Loaded credentials for https://api.wandb.ai from /ghome/group06/.netrc.
wandb: Currently logged in as: arnaumarcosalmansa (mcv-team-6) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 6zm9x6hz
wandb: Tracking run with wandb version 0.24.0
wandb: Run data is saved locally in wandb/run-20260118_164322-6zm9x6hz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Test run
wandb: ‚≠êÔ∏è View project at https://wandb.ai/mcv-team-6/C3-Week4
wandb: üöÄ View run at https://wandb.ai/mcv-team-6/C3-Week4/runs/6zm9x6hz
/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train.py ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type               | Params | Mode  | FLOPs
-----------------------------------------------------------------
0 | model     | SmallLeNet         | 24.3 K | train | 0    
1 | loss_fn   | CrossEntropyLoss   | 0      | train | 0    
2 | train_acc | MulticlassAccuracy | 0      | train | 0    
3 | val_acc   | MulticlassAccuracy | 0      | train | 0    
-----------------------------------------------------------------
24.3 K    Trainable params
0         Non-trainable params
24.3 K    Total params
0.097     Total estimated model params size (MB)
17        Modules in train mode
0         Modules in eval mode
0         Total Flops
Traceback (most recent call last):
  File "/export/home/group06/workspace/project-team-6/Week4/train.py", line 47, in <module>
    trainer.fit(train_model, train_loader, test_loader)
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 584, in fit
    call._call_and_handle_interrupt(
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 630, in _fit_impl
    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1079, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1121, in _run_stage
    self._run_sanity_check()
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1150, in _run_sanity_check
    val_loop.run()
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 153, in run
    return self.on_run_end()
           ^^^^^^^^^^^^^^^^^
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 296, in on_run_end
    self._on_evaluation_epoch_end()
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 379, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/ghome/group06/miniconda3/envs/c3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
TypeError: BasicTrainingModule.on_validation_epoch_end() missing 1 required positional argument: 'outputs'
