{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "573e64cf",
         "metadata": {},
         "source": [
            "# Introduction\n",
            "\n",
            "The experimentation pipeline will be the following: We'll take a baseline configuration detailed below, and we're going to perform experiments in diferent aspects of the whole pipeline. As we make those experiments, we'll update the baseline keeping the balance with the best results from the previous experiments and hyperparameters that don't compromise the experimentation speed. We're going to use the following baseline for experimentation:\n",
            "- Descriptor: SIFT, as the common algorithm for feature extraction in classic literature\n",
            "- Number of features: 1000\n",
            "- Size of codebook: 512 (For initial fast clustering experimentation)\n",
            "- Normalization: L2 in histograms\n",
            "- Spatial Pyramids: No pyramid (no level)\n",
            "- Dimensionality reuction: None (first we try with the whole data)\n",
            "- Classifier: Logistic Regression (fast and easy hyperparameters for base experimentation)\n",
            "\n",
            "\n",
            "With this pipeline, we're going to try:\n",
            "- Number of local features in descriptors\n",
            "- SIFT / AKAZE / ORB / Dense SIFT\n",
            "- Spatial pyramids vs no spatial pyramids\n",
            "- Try normalization and scale\n",
            "- Size of codebook\n",
            "- Try dimensionality reduction\n",
            "- Classifiers: Logistic Regression vs SVM vs KNN\n",
            "- Fisher Vectors\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "41d2ddfb",
         "metadata": {},
         "source": [
            "# Experiments"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9aabddbf",
         "metadata": {},
         "outputs": [],
         "source": [
            "from main import *\n",
            "from bovw import *"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e0e3e984",
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import random\n",
            "import numpy as np\n",
            "\n",
            "%matplotlib inline\n",
            "from matplotlib import pyplot as plt"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "6d716a67",
         "metadata": {},
         "outputs": [],
         "source": [
            "SEED = 42\n",
            "\n",
            "random.seed(SEED)\n",
            "np.random.seed(SEED)\n",
            "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "638c63bd",
         "metadata": {},
         "outputs": [],
         "source": [
            "data_train = Dataset(ImageFolder=\"../data/places_reduced/train\")\n",
            "data_test = Dataset(ImageFolder=\"../data/places_reduced/val\")\n",
            "\n",
            "len(data_train), len(data_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c974e5fa",
         "metadata": {},
         "outputs": [],
         "source": [
            "random.shuffle(data_train)\n",
            "random.shuffle(data_test)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "6d6a51bb",
         "metadata": {},
         "outputs": [],
         "source": [
            "sample_idx = 76\n",
            "print(data_train[sample_idx][1])\n",
            "plt.imshow(np.array(data_train[sample_idx][0]))\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "77301255",
         "metadata": {},
         "outputs": [],
         "source": [
            "train_class_counter = Counter(entry[1] for entry in data_train)\n",
            "test_class_counter = Counter(entry[1] for entry in data_test)\n",
            "\n",
            "classes = sorted(train_class_counter.keys())  # or union with test if needed\n",
            "train_counts = [train_class_counter[c] for c in classes]\n",
            "test_counts = [test_class_counter[c] for c in classes]\n",
            "\n",
            "width = 0.4\n",
            "x = range(len(classes))\n",
            "\n",
            "plt.bar([xi - width/2 for xi in x], train_counts, width=width, label=\"Train\")\n",
            "plt.bar([xi + width/2 for xi in x], test_counts, width=width, label=\"Test\")\n",
            "\n",
            "plt.xticks(x, classes)\n",
            "plt.ylabel(\"Frequency\")\n",
            "plt.title(\"Class Distribution: Train vs Test\")\n",
            "plt.legend()\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b3973f94",
         "metadata": {},
         "source": [
            "All classes have 800 training images except for class 4 (\"industrial and construction\"), which has 700.\n",
            "\n",
            "All classes have 200 test samples."
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b61ba66e",
         "metadata": {},
         "source": [
            "## A) Descriptors (SIFT vs AKAZE vs ORB) and number of features\n",
            "\n",
            "Comparision of descriptors (SIFT vs AKAZE vs ORB) while trying different hyperparameters on the descriptors (including the number of features)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "fb0fb49f",
         "metadata": {},
         "outputs": [],
         "source": [
            "bovw_params = {\n",
            "    \"detector_type\": \"DSIFT\",\n",
            "    \"codebook_size\": 100, \n",
            "    \"detector_kwargs\": {\"nfeatures\": 100},\n",
            "    \"dense_kwargs\": {\"step\": 16, \"size\": 16}\n",
            "}\n",
            "\n",
            "classifier_cls = SVC\n",
            "classifier_params = {\n",
            "    \"kernel\": 'rbf', \n",
            "}\n",
            "\n",
            "scores = cross_validate_bovw(\n",
            "    data_train,\n",
            "    bovw_kwargs=bovw_params,\n",
            "    classifier_cls=classifier_cls,\n",
            "    classifier_kwargs=classifier_params\n",
            ")\n",
            "\n",
            "scores.test.accuracy.mean"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "bb38e0fd",
         "metadata": {},
         "source": [
            "## B) Density vs Non Density (SIFT vs Dense SIFT)\n",
            "\n",
            "ATENCIÓN: AQUÍ ASUMO QUE SIFT SERÁ EL QUE FUNCIONARÁ MEJOR, CANVIAR SI NO ES EL CASO\n",
            "\n",
            "Since SIFT was the best descriptor, we compare it with Dense SIFT"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "50805c35",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "90499b27",
         "metadata": {},
         "source": [
            "## C) Size of codebook\n",
            "\n",
            "Try for different codebook sizes (k) "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d2e5b209",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "3737cfdb",
         "metadata": {},
         "source": [
            "## D) Spatial Pyramids\n",
            "\n",
            "Comaprision between using and not using spatial pyramids"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e66b8af1",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "0b8fcb2e",
         "metadata": {},
         "source": [
            "## E) Classifiers and Normalization\n",
            "\n",
            "Since the way the data is normalized and preprocessed can depend on the classifier, we're going to try this along the different classifiers and it's hyperparameter search for Logistic Regression, SVM, KNN"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b51dc115",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "3eb4c61a",
         "metadata": {},
         "source": [
            "## F) Dimensionality Reduction\n",
            "\n",
            "We're going to try PCA, SVD, LDA, t-SNE"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "74f49f06",
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "markdown",
         "id": "02dea43e",
         "metadata": {},
         "source": [
            "## G) Fisher Vectors\n",
            "\n",
            "Finally, we're going to do a fisher vector approach"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5ebf685a",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.8"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
